## Vis√£o Geral

Este reposit√≥rio foi criado com o intuito de disponibilizar os resultados da abordagem estat√≠stica delineada no trabalho, juntamente com o c√≥digo utilizado para implement√°-la.

### üî¨ An√°lise de M√©tricas de Similaridade Textual

Esta an√°lise compara diferentes modelos com base em m√©tricas de similaridade textual.

* **C√≥digo**: `comparacao_calculacao.ipynb`
    * *Notebook Jupyter contendo o script para a compara√ß√£o estat√≠stica de m√©tricas de avalia√ß√£o de modelos.*
* **Resultados**: `resultados_comparacao_modelos.csv`
    * *Arquivo CSV com os dados detalhados das compara√ß√µes estat√≠sticas entre os modelos para as m√©tricas de similaridade.*

### ‚ùì An√°lise de Perguntas e Respostas (Q&A)

Esta an√°lise avalia a performance de modelos em tarefas de Perguntas e Respostas, comparando suas acur√°cias.

* **C√≥digo**: `comparacao_calculacao_qa.ipynb`
    * *Notebook Jupyter com o script para a compara√ß√£o de acur√°cia entre modelos em benchmarks de Q&A, utilizando o intervalo de confian√ßa para a diferen√ßa entre duas propor√ß√µes independentes.*
* **Resultados**: `resultados_comparacao_acuracia_qa.csv`
    * *Arquivo CSV com os resultados das compara√ß√µes de acur√°cia, incluindo intervalos de confian√ßa e signific√¢ncia estat√≠stica para cada modelo em rela√ß√£o ao modelo base nos benchmarks de Q&A.*
